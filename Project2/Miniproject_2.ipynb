{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:08:59.505960Z",
     "start_time": "2020-04-23T14:08:59.501969Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import empty, zeros\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:41:49.506110Z",
     "start_time": "2020-04-23T13:41:49.500124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5001063b0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:11.925449Z",
     "start_time": "2020-04-23T13:16:11.920432Z"
    }
   },
   "outputs": [],
   "source": [
    "class Module(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, *input_):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def param(self):\n",
    "        return []\n",
    "    \n",
    "    def update(self, lr):\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:12.013034Z",
     "start_time": "2020-04-23T13:16:11.927412Z"
    }
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, N_in, N_out):\n",
    "        super(Linear, self).__init__()\n",
    "        self.N_in = N_in\n",
    "        self.N_out = N_out\n",
    "        \n",
    "        self.W = empty((N_in, N_out)).normal_()\n",
    "        self.b = empty((1, N_out)).normal_()\n",
    "        \n",
    "        self.gradW = zeros(self.W.shape).normal_()\n",
    "        self.gradb = zeros(self.b.shape).normal_()\n",
    "        \n",
    "    def forward(self, *input_):\n",
    "        # out = W * input + b\n",
    "        x = input_[0].clone()\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        return self.x.mm(self.W) + self.b\n",
    "        \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        # grad_w += input * x^(l-1).t()\n",
    "        # grad_b += input\n",
    "        # out = w.t() * input\n",
    "        # input = grad of activation function, i.e. dl/ds^(l)\n",
    "        # x^(l-1) = input of the forward pass\n",
    "        input_ = gradwrtoutput[0].clone()\n",
    "        \n",
    "        self.gradW += self.x.t().mm(input_)\n",
    "        self.gradb += input_.sum(0)\n",
    "        \n",
    "        return input_.mm(self.W.t())\n",
    "        \n",
    "    def param(self):\n",
    "        return [(self.W, self.gradW), (self.b, self.gradb)]\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.W.sub_(lr * self.gradW)\n",
    "        self.b.sub_(lr * self.gradb)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.gradW = zeros(self.W.shape)\n",
    "        self.gradb = zeros(self.b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:12.093803Z",
     "start_time": "2020-04-23T13:16:12.014017Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "        \n",
    "    def forward(self, *input_):\n",
    "        s = input_[0].clone()\n",
    "        self.s = s\n",
    "        \n",
    "        s[s < 0] = 0.\n",
    "        \n",
    "        return s\n",
    "        \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        # out = f'(s^(l)) * input\n",
    "        # s^(l) = input of forward pass\n",
    "        # input = grad of next layer\n",
    "        input_ = gradwrtoutput[0].clone()\n",
    "        \n",
    "        out = self.s.clone()\n",
    "        out[out > 0] = 1\n",
    "        out[out < 0] = 0\n",
    "        \n",
    "        \n",
    "        return out.mul(input_)\n",
    "        \n",
    "    def param(self):\n",
    "        return []\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:12.223661Z",
     "start_time": "2020-04-23T13:16:12.094801Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tanh(Module):\n",
    "    def __init__(self):\n",
    "        super(Tanh, self).__init__()\n",
    "        \n",
    "    def forward(self, *input_):\n",
    "        s = input_[0].clone()\n",
    "        self.s = s\n",
    "        \n",
    "        return s.tanh()\n",
    "        \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        # out = f'(s^(l)) * input\n",
    "        # s^(l) = input of forward pass\n",
    "        # input = grad of next layer\n",
    "        input_ = gradwrtoutput[0].clone()\n",
    "        \n",
    "        out = self.s.clone()\n",
    "        out = 1 - out.tanh().pow(2)\n",
    "        \n",
    "        return out.mul(input_)\n",
    "        \n",
    "    def param(self):\n",
    "        return []\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:12.303690Z",
     "start_time": "2020-04-23T13:16:12.224658Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sequential(Module):\n",
    "    def __init__(self, *modules):\n",
    "        super(Sequential, self).__init__()\n",
    "        self.modules = modules\n",
    "        \n",
    "    def forward(self, *input_):\n",
    "        x = input_[0].clone()\n",
    "        \n",
    "        for m in self.modules:\n",
    "            x = m.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def backward(self, *gradwrtoutput):\n",
    "        x = gradwrtoutput[0].clone()\n",
    "        \n",
    "        for i, m in enumerate(reversed(self.modules)):\n",
    "            #print(\"{} : {}\".format(i, x))\n",
    "            x = m.backward(x)\n",
    "        \n",
    "    def param(self):\n",
    "        params = []\n",
    "        \n",
    "        for m in self.modules:\n",
    "            for param in m.param():\n",
    "                params.append(param)\n",
    "        \n",
    "        return params\n",
    "\n",
    "    def update(self, lr):\n",
    "        for m in self.modules:\n",
    "            m.update(lr)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for m in self.modules:\n",
    "            m.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:36:51.439964Z",
     "start_time": "2020-04-23T13:36:51.430020Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"class Loss: \n",
    "    ...\n",
    "\"\"\"\n",
    "class LossMSE(Module):\n",
    "    def __init__(self):\n",
    "        super(LossMSE, self).__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self, y, target):\n",
    "        # out = e^2\n",
    "        # e = (y - f(x))\n",
    "        self.y = y.clone()\n",
    "        target_onehot = zeros((target.shape[0], 2)) \n",
    "        self.target = target_onehot.scatter_(1, target.view(-1, 1), 1)\n",
    "        \n",
    "        self.e = (self.y - self.target)\n",
    "        self.n = self.y.size(0)\n",
    "        \n",
    "        \n",
    "        return self.e.pow(2).sum()\n",
    "        \n",
    "    def backward(self):\n",
    "        # out = 2 * e\n",
    "        \n",
    "        return 2 * self.e # / self.n        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T16:20:46.938653Z",
     "start_time": "2020-04-23T16:20:46.930708Z"
    }
   },
   "outputs": [],
   "source": [
    "class LossCrossEntropy(Module):\n",
    "    def __init__(self):\n",
    "        super(LossCrossEntropy, self).__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self, y, target):\n",
    "        # out = e^2\n",
    "        # e = (y - f(x))\n",
    "        self.y = y.clone()\n",
    "        self.target = target.clone()\n",
    "        sm = torch.softmax(self.y, dim=1)\n",
    "        likelihood = -torch.log(torch.clamp(sm[range(target.size(0)), target], min=1e-3, max=None))\n",
    "        return likelihood.mean()\n",
    "        \n",
    "    def backward(self):\n",
    "        sm = torch.softmax(self.y, dim=1)\n",
    "        target_onehot = zeros((self.target.shape[0], 2)) \n",
    "        target_onehot = target_onehot.scatter_(1, self.target.view(-1, 1), 1)\n",
    "        return sm - target_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T16:17:38.388275Z",
     "start_time": "2020-04-23T16:17:38.371321Z"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def step(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, model, nb_epochs = 50, mini_batch_size=1, lr=1e-4, criterion=LossMSE()):\n",
    "        super(SGD, self).__init__()\n",
    "        self.model = model\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.criterion = criterion\n",
    "    \n",
    "    def step(self):\n",
    "        self.model.update(self.lr)\n",
    "        \n",
    "    # Train function?\n",
    "    def train(self, train_input, train_target, verbose=True):\n",
    "        \n",
    "        for e in range(self.nb_epochs):\n",
    "            sum_loss = 0.\n",
    "        \n",
    "            for b in range(0, train_input.size(0), self.mini_batch_size):\n",
    "                self.model.zero_grad()\n",
    "                output = self.model.forward(train_input.narrow(0, b, self.mini_batch_size))\n",
    "                #print(output)\n",
    "                loss = self.criterion.forward(output, train_target.narrow(0, b, self.mini_batch_size))\n",
    "                # print(loss)\n",
    "            \n",
    "                sum_loss += loss\n",
    "            \n",
    "                l_grad = self.criterion.backward()\n",
    "                self.model.backward(l_grad)\n",
    "                #print(model.param()[0])\n",
    "                self.step()\n",
    "            \n",
    "            #print(model.param()[0])\n",
    "            if verbose:\n",
    "                print(\"{} iteration: loss={}\".format(e, sum_loss))\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:23:35.545513Z",
     "start_time": "2020-04-23T14:23:35.531552Z"
    }
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def cross_validate(self, k=5, possible_lrs=[1e-5, 1e-4, 1e-3, 1e-2]):\n",
    "        train_datasets = []\n",
    "        test_datasets = []\n",
    "        for i in range(k):\n",
    "            train_datasets.append(generate_disc_set(1000))\n",
    "            test_datasets.append(generate_disc_set(1000))\n",
    "        scores = {}\n",
    "        score_means = {}\n",
    "        score_vars = {}\n",
    "        for lr in possible_lrs:\n",
    "            print(\"Validating:\", lr)\n",
    "            scores[lr] = []\n",
    "            for (train_input, train_target), (test_input, test_target) in zip(train_datasets, test_datasets):\n",
    "                optimizer.model = Sequential(Linear(2, 25), ReLU(), Linear(25, 25), ReLU(), Linear(25, 25), ReLU(), Linear(25, 2)) \n",
    "                optimizer.lr = lr\n",
    "                self.model = optimizer.train(train_input, train_target, verbose=False)\n",
    "                accuracy = self.test(test_input, test_target)\n",
    "                scores[lr].append(accuracy)\n",
    "            scores[lr] = torch.FloatTensor(scores[lr])\n",
    "            score_means[lr] = torch.mean(scores[lr])\n",
    "            score_vars[lr] = torch.std(scores[lr])\n",
    "            \n",
    "        return score_means, score_vars\n",
    "    \n",
    "    def test(self, test_input, test_target):\n",
    "        num_samples = test_input.size(0)\n",
    "        prediction = self.model.forward(test_input)\n",
    "        predicted_class = torch.argmax(prediction, axis=1)\n",
    "        accuracy = sum(predicted_class == test_target).float() / num_samples\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:12.778279Z",
     "start_time": "2020-04-23T13:16:12.613462Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input = empty(nb, 2).uniform_(-1, 1)\n",
    "    target = input.pow(2).sum(1).sub(2 / math.pi).sign().add(1).div(2).long()\n",
    "    return input, target\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T13:16:12.843629Z",
     "start_time": "2020-04-23T13:16:12.779272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8252,  0.2783],\n",
       "        [ 0.0929,  0.2911],\n",
       "        [ 0.4758,  0.5343],\n",
       "        ...,\n",
       "        [-0.2414, -0.2005],\n",
       "        [-0.9865, -0.1295],\n",
       "        [-0.6723, -0.1999]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:24:01.823320Z",
     "start_time": "2020-04-23T14:24:01.816333Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential(Linear(2, 25), ReLU(),\n",
    "                   Linear(25, 25), ReLU(),\n",
    "                   Linear(25, 25), ReLU(),\n",
    "                   Linear(25, 2))\n",
    "# model = Sequential(Linear(2, 25), Tanh(),\n",
    "#                    Linear(25, 25), Tanh(),\n",
    "#                    Linear(25, 25), Tanh(),\n",
    "#                    Linear(25, 2))\n",
    "\n",
    "optimizer = SGD(model, mini_batch_size=5)\n",
    "evaluator = Evaluator(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T14:27:14.564365Z",
     "start_time": "2020-04-23T14:24:03.059499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating: 1e-05\n",
      "Validating: 0.0001\n",
      "Validating: 0.001\n",
      "Validating: 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({1e-05: tensor(0.8174),\n",
       "  0.0001: tensor(0.7730),\n",
       "  0.001: tensor(0.5034),\n",
       "  0.01: tensor(0.5034)},\n",
       " {1e-05: tensor(0.0337),\n",
       "  0.0001: tensor(0.2425),\n",
       "  0.001: tensor(0.0098),\n",
       "  0.01: tensor(0.0098)})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T16:23:21.386305Z",
     "start_time": "2020-04-23T16:23:20.353500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration: loss=20.889606475830078\n",
      "1 iteration: loss=7.32117223739624\n",
      "2 iteration: loss=3.96122407913208\n",
      "3 iteration: loss=1.9598121643066406\n",
      "4 iteration: loss=1.200587272644043\n",
      "5 iteration: loss=0.9994472861289978\n",
      "6 iteration: loss=0.9138118028640747\n",
      "7 iteration: loss=0.8422287702560425\n",
      "8 iteration: loss=0.7800658941268921\n",
      "9 iteration: loss=0.7308159470558167\n",
      "10 iteration: loss=0.6977884769439697\n",
      "11 iteration: loss=0.6656010746955872\n",
      "12 iteration: loss=0.6381933093070984\n",
      "13 iteration: loss=0.6255884170532227\n",
      "14 iteration: loss=0.599713146686554\n",
      "15 iteration: loss=0.5800283551216125\n",
      "16 iteration: loss=0.5602816343307495\n",
      "17 iteration: loss=0.5460494756698608\n",
      "18 iteration: loss=0.5315064787864685\n",
      "19 iteration: loss=0.5161387324333191\n",
      "20 iteration: loss=0.5063460469245911\n",
      "21 iteration: loss=0.49479174613952637\n",
      "22 iteration: loss=0.48522859811782837\n",
      "23 iteration: loss=0.47490543127059937\n",
      "24 iteration: loss=0.4643429219722748\n",
      "25 iteration: loss=0.453312486410141\n",
      "26 iteration: loss=0.44643983244895935\n",
      "27 iteration: loss=0.4376421868801117\n",
      "28 iteration: loss=0.42511260509490967\n",
      "29 iteration: loss=0.41316092014312744\n",
      "30 iteration: loss=0.4049822688102722\n",
      "31 iteration: loss=0.3983044922351837\n",
      "32 iteration: loss=0.39617758989334106\n",
      "33 iteration: loss=0.38704922795295715\n",
      "34 iteration: loss=0.3885802626609802\n",
      "35 iteration: loss=0.38130155205726624\n",
      "36 iteration: loss=0.3719906210899353\n",
      "37 iteration: loss=0.3684185743331909\n",
      "38 iteration: loss=0.36743342876434326\n",
      "39 iteration: loss=0.3601005971431732\n",
      "40 iteration: loss=0.36353588104248047\n",
      "41 iteration: loss=0.3567644953727722\n",
      "42 iteration: loss=0.3493037223815918\n",
      "43 iteration: loss=0.34272849559783936\n",
      "44 iteration: loss=0.3374839127063751\n",
      "45 iteration: loss=0.3336322009563446\n",
      "46 iteration: loss=0.3285030126571655\n",
      "47 iteration: loss=0.3252321481704712\n",
      "48 iteration: loss=0.3216571807861328\n",
      "49 iteration: loss=0.31787246465682983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9790)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr = 1e-4\n",
    "model = Sequential(Linear(2, 25), ReLU(),\n",
    "                   Linear(25, 25), ReLU(),\n",
    "                   Linear(25, 25), ReLU(),\n",
    "                   Linear(25, 2))\n",
    "optimizer = SGD(model, lr=best_lr, mini_batch_size=100, criterion=LossCrossEntropy())\n",
    "model = optimizer.train(train_input, train_target)\n",
    "evaluator.model = model\n",
    "evaluator.test(test_input, test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
